#!/usr/bin/env python3
"""
Daemon do pobierania transakcji z perpetualMarket z dYdX API dzieÅ„ po dniu.

Skrypt przetwarza dane w porcjach po 1 dniu wstecz. Przechodzi do kolejnego dnia
tylko gdy bezbÅ‚Ä™dnie zakoÅ„czy przetwarzanie aktualnego dnia.

Logi:
  - GÅ‚Ã³wne logi: .dev/logs/dydx_perpetual_market_trades_service.log
  - Logi dni: .dev/logs/dydx_perpetual_market_trades_days.log (tylko dni i liczba rekordÃ³w)
"""

import os
import sys
import argparse
import time
import json
from datetime import datetime, timezone, timedelta
from typing import List, Dict, Any, Optional
from pathlib import Path

# Dodaj Å›cieÅ¼kÄ™ projektu
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from dotenv import load_dotenv
import psycopg2
from psycopg2.extras import execute_values
from loguru import logger
from src.providers.dydx_indexer_provider import DydxIndexerProvider
from src.scripts.populate_dydx_perpetual_market_trades import (
    get_db_connection,
    insert_market_trades,
    get_trades_with_retry,
    MAX_RETRIES_PER_BATCH,
    RETRY_DELAY_BASE,
    RETRY_DELAY_MAX,
    MAX_CONSECUTIVE_FAILURES
)

# Konfiguracja loggera
logger.remove()

# GÅ‚Ã³wny logger (do pliku usÅ‚ugi)
service_log_file = os.path.join(
    os.path.dirname(__file__), '..', '..', '.dev', 'logs',
    'dydx_perpetual_market_trades_service.log'
)
os.makedirs(os.path.dirname(service_log_file), exist_ok=True)
logger.add(service_log_file, level="INFO", format="{time:YYYY-MM-DD HH:mm:ss} | {level:<7} | {message}")

# Plik logÃ³w dla dni (tylko dni i liczba rekordÃ³w)
days_log_file = os.path.join(
    os.path.dirname(__file__), '..', '..', '.dev', 'logs',
    'dydx_perpetual_market_trades_days.log'
)

# NIE dodajemy loggera do stderr - tylko do pliku (daemon dziaÅ‚a w tle)


def get_progress_file(ticker: str) -> str:
    """Zwraca Å›cieÅ¼kÄ™ do pliku postÄ™pu dla danego tickera."""
    return os.path.join(
        os.path.dirname(__file__), '..', '..', '.dev', 'logs',
        f'dydx_perpetual_market_trades_progress_{ticker}.json'
    )


def load_progress(conn, ticker: str) -> Optional[Dict]:
    """Wczytuje postÄ™p z bazy danych."""
    try:
        with conn.cursor() as cur:
            select_sql = """
                SELECT ticker, processing_date, total_trades, last_update, attempts
                FROM dydx_perpetual_market_trades_progress
                WHERE ticker = %s
            """
            cur.execute(select_sql, (ticker,))
            row = cur.fetchone()
            
            if row:
                return {
                    'ticker': row[0],
                    'current_date': row[1].isoformat() if row[1] else None,
                    'total_trades': row[2] or 0,
                    'last_update': row[3].isoformat() if row[3] else None,
                    'attempts': row[4] if row[4] else []
                }
    except Exception as e:
        logger.warning(f"BÅ‚Ä…d wczytywania postÄ™pu z bazy: {e}")
    return None


def save_progress(conn, ticker: str, current_date: datetime, total_trades: int, attempts: List[Dict]):
    """Zapisuje postÄ™p do bazy danych."""
    try:
        with conn.cursor() as cur:
            # Przygotuj dane
            last_update = datetime.now(timezone.utc)
            attempts_json = json.dumps(attempts) if attempts else json.dumps([])
            
            # INSERT ... ON CONFLICT UPDATE (upsert)
            insert_sql = """
                INSERT INTO dydx_perpetual_market_trades_progress (
                    ticker, processing_date, total_trades, last_update, attempts
                ) VALUES (%s, %s, %s, %s, %s::jsonb)
                ON CONFLICT (ticker) DO UPDATE SET
                    processing_date = EXCLUDED.processing_date,
                    total_trades = EXCLUDED.total_trades,
                    last_update = EXCLUDED.last_update,
                    attempts = EXCLUDED.attempts,
                    updated_at = CURRENT_TIMESTAMP
            """
            
            cur.execute(
                insert_sql,
                (
                    ticker,
                    current_date,
                    total_trades,
                    last_update,
                    attempts_json
                )
            )
            conn.commit()
    except Exception as e:
        logger.warning(f"BÅ‚Ä…d zapisywania postÄ™pu do bazy: {e}")
        conn.rollback()


def process_single_day(
    provider: DydxIndexerProvider,
    conn,
    ticker: str,
    target_date: datetime
) -> tuple[bool, int, List[Dict]]:
    """
    Przetwarza transakcje dla jednego dnia.
    
    Returns:
        (success, total_trades, attempts) gdzie:
        - success: True jeÅ›li dzieÅ„ zostaÅ‚ bezbÅ‚Ä™dnie przetworzony
        - total_trades: ÅÄ…czna liczba zapisanych transakcji
        - attempts: Lista prÃ³b z liczbÄ… rekordÃ³w
    """
    # Oblicz zakres dat dla dnia (00:00:00 - 23:59:59 UTC)
    day_start = target_date.replace(hour=0, minute=0, second=0, microsecond=0)
    day_end = day_start + timedelta(days=1) - timedelta(microseconds=1)
    
    logger.info(f"ğŸ“… Przetwarzanie dnia: {day_start.date()} ({day_start} - {day_end})")
    
    all_trades = []  # UÅ¼ywane tylko do zliczania i koÅ„cowego zapisu pozostaÅ‚ych
    attempts = []
    current_end = day_end
    batch_count = 0
    consecutive_failures = 0
    last_successful_batch_time = datetime.now(timezone.utc)
    max_batches = 10000  # Zabezpieczenie
    total_inserted = 0  # ÅÄ…czna liczba zapisanych transakcji
    
    logger.info(f"ğŸ”„ Rozpoczynam pobieranie dla dnia {day_start.date()} (od {day_end} do {day_start})")
    
    while current_end >= day_start and batch_count < max_batches:
        # SprawdÅº czy nie ma zbyt dÅ‚ugiej przerwy bez sukcesu
        time_since_last_success = (datetime.now(timezone.utc) - last_successful_batch_time).total_seconds()
        if time_since_last_success > 1800:  # 30 minut bez sukcesu
            logger.warning(f"âš ï¸ Brak sukcesu przez {time_since_last_success/60:.1f} minut - VPN moÅ¼e siÄ™ przeÅ‚Ä…czaÄ‡, czekam dÅ‚uÅ¼ej...")
            wait_time = min(RETRY_DELAY_MAX, time_since_last_success / 10)
            logger.info(f"â³ Czekam {wait_time:.0f}s przed kolejnÄ… prÃ³bÄ…...")
            time.sleep(wait_time)
            last_successful_batch_time = datetime.now(timezone.utc)
        
        # Pobierz transakcje z retry
        attempt_start = datetime.now(timezone.utc)
        logger.debug(f"PrÃ³ba pobrania batch {batch_count + 1} dla dnia {day_start.date()} (od {current_end} do {day_start})")
        
        trades = get_trades_with_retry(
            provider=provider,
            ticker=ticker,
            created_before_or_at=current_end,
            created_on_or_after=day_start,
            consecutive_failures=consecutive_failures
        )
        attempt_end = datetime.now(timezone.utc)
        attempt_duration = (attempt_end - attempt_start).total_seconds()
        
        if trades is None:
            consecutive_failures += 1
            logger.warning(f"âš ï¸ Nie udaÅ‚o siÄ™ pobraÄ‡ batch {batch_count + 1}. BÅ‚Ä™dy z rzÄ™du: {consecutive_failures}")
            
            attempts.append({
                'batch': batch_count + 1,
                'success': False,
                'trades_count': 0,
                'duration_seconds': attempt_duration,
                'timestamp': attempt_start.isoformat()
            })
            
            # Po zbyt wielu bÅ‚Ä™dach, zwiÄ™ksz opÃ³Åºnienie
            if consecutive_failures >= MAX_CONSECUTIVE_FAILURES:
                logger.info(f"â³ {consecutive_failures} kolejnych bÅ‚Ä™dÃ³w - VPN moÅ¼e siÄ™ przeÅ‚Ä…czaÄ‡, czekam dÅ‚uÅ¼ej...")
            
            wait_time = min(RETRY_DELAY_BASE * (2 ** consecutive_failures) * (1 + consecutive_failures / 2), RETRY_DELAY_MAX)
            logger.info(f"â³ Czekam {wait_time:.0f}s przed ponownÄ… prÃ³bÄ… (VPN moÅ¼e siÄ™ przeÅ‚Ä…czaÄ‡)...")
            time.sleep(wait_time)
            continue
        
        if not trades:
            logger.debug(f"Brak wiÄ™cej transakcji dla dnia {day_start.date()} (batch {batch_count + 1})")
            attempts.append({
                'batch': batch_count + 1,
                'success': True,
                'trades_count': 0,
                'duration_seconds': attempt_duration,
                'timestamp': attempt_start.isoformat(),
                'note': 'Brak transakcji'
            })
            break
        
        # Sukces - resetuj liczniki
        consecutive_failures = 0
        last_successful_batch_time = datetime.now(timezone.utc)
        
        batch_count += 1
        
        logger.info(f"âœ“ Batch {batch_count}: pobrano {len(trades)} transakcji (czas: {attempt_duration:.1f}s)")
        
        # Zapisz batch od razu do bazy
        inserted = 0
        try:
            inserted = insert_market_trades(conn, ticker, trades)
            total_inserted += inserted
            logger.info(f"ğŸ’¾ Zapisano {inserted} transakcji z batcha {batch_count} do bazy")
        except Exception as e:
            logger.error(f"âŒ BÅ‚Ä…d zapisywania batcha {batch_count}: {e}")
            # Nie przerywamy - kontynuujemy, ale zapisujemy do listy na pÃ³Åºniej
            all_trades.extend(trades)
        
        attempts.append({
            'batch': batch_count,
            'success': True,
            'trades_count': len(trades),
            'inserted_count': inserted,
            'duration_seconds': attempt_duration,
            'timestamp': attempt_start.isoformat()
        })
        
        # ZnajdÅº najstarszÄ… transakcjÄ™ z tego batcha
        oldest_trade = min(trades, key=lambda t: t.get('createdAt', current_end))
        oldest_date = oldest_trade.get('createdAt')
        
        if isinstance(oldest_date, datetime):
            current_end = oldest_date
        elif isinstance(oldest_date, str):
            try:
                current_end = datetime.fromisoformat(oldest_date.replace('Z', '+00:00'))
            except:
                logger.error(f"BÅ‚Ä…d parsowania daty: {oldest_date}")
                return False, total_inserted, attempts
        else:
            logger.error(f"NieprawidÅ‚owy format daty: {oldest_date}")
            return False, total_inserted, attempts
        
        # Logowanie postÄ™pu co 10 batchy
        if batch_count % 10 == 0:
            logger.info(f"ğŸ“Š PostÄ™p: {batch_count} batchy, {total_inserted} transakcji zapisanych, current_end: {current_end}, day_start: {day_start}")
        
        # JeÅ›li najstarsza transakcja jest przed poczÄ…tkiem dnia, zakoÅ„cz
        if current_end < day_start:
            logger.info(f"âœ“ OsiÄ…gniÄ™to poczÄ…tek dnia ({day_start}). KoÅ„czÄ™ pobieranie.")
            break
        
        # JeÅ›li pobraliÅ›my mniej niÅ¼ limit, to znaczy Å¼e to koniec
        if len(trades) < 100:
            logger.info(f"âœ“ Otrzymano mniej niÅ¼ 100 transakcji ({len(trades)}). KoÅ„czÄ™ pobieranie.")
            break
        
        logger.debug(f"Batch {batch_count}: pobrano {len(trades)} transakcji, kontynuujÄ™ od {current_end}")
    
    # Zapisz pozostaÅ‚e transakcje do bazy (jeÅ›li sÄ… - tylko te, ktÃ³re nie zostaÅ‚y zapisane z powodu bÅ‚Ä™du)
    logger.info(f"ğŸ“ ZakoÅ„czono pobieranie dla dnia {day_start.date()}. ÅÄ…cznie zapisano {total_inserted} transakcji w {batch_count} batchach.")
    
    if all_trades:
        try:
            logger.info(f"ğŸ’¾ ZapisujÄ™ {len(all_trades)} pozostaÅ‚ych transakcji do bazy (z bÅ‚Ä™dÃ³w)...")
            inserted = insert_market_trades(conn, ticker, all_trades)
            total_inserted += inserted
            logger.info(f"âœ“ Zapisano dodatkowo {inserted} transakcji do bazy dla dnia {day_start.date()}")
        except Exception as e:
            logger.error(f"âŒ BÅ‚Ä…d zapisywania pozostaÅ‚ych transakcji dla dnia {day_start.date()}: {e}")
    
    # Log do pliku dni
    total_attempts = len(attempts)
    successful_attempts = sum(1 for a in attempts if a['success'] and a['trades_count'] > 0)
    total_trades_from_attempts = sum(a['trades_count'] for a in attempts)
    
    # Log do pliku dni - tylko informacje o dniu i liczbie rekordÃ³w
    if total_inserted > 0:
        days_log_msg = f"âœ“ {day_start.date()} | {total_inserted} rekordÃ³w | {successful_attempts}/{total_attempts} prÃ³b udanych | {total_trades_from_attempts} transakcji pobranych"
    else:
        days_log_msg = f"â„¹ï¸ {day_start.date()} | 0 rekordÃ³w | Brak transakcji"
    
    # UÅ¼yj bezpoÅ›redniego zapisu do pliku, bo logger moÅ¼e nie dziaÅ‚aÄ‡ poprawnie z filtrem
    with open(days_log_file, 'a', encoding='utf-8') as f:
        f.write(f"{datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S')} | {days_log_msg}\n")
    
    return True, total_inserted, attempts


def main():
    parser = argparse.ArgumentParser(description='Daemon do pobierania transakcji z perpetualMarket dzieÅ„ po dniu')
    parser.add_argument('--ticker', type=str, default='BTC-USD', help='Symbol rynku (domyÅ›lnie: BTC-USD)')
    parser.add_argument('--days-back-start', type=int, default=1, help='Od ilu dni wstecz zaczÄ…Ä‡ (domyÅ›lnie: 1)')
    parser.add_argument('--max-days', type=int, help='Maksymalna liczba dni do przetworzenia (None = bez limitu)')
    parser.add_argument('--delay-between-days', type=int, default=5, help='OpÃ³Åºnienie miÄ™dzy dniami w sekundach (domyÅ›lnie: 5)')
    
    args = parser.parse_args()
    
    load_dotenv()
    
    logger.info("="*70)
    logger.info(f"Uruchamianie daemona dla {args.ticker}")
    logger.info(f"Start od {args.days_back_start} dni wstecz")
    logger.info("="*70)
    
    # PoÅ‚Ä…cz z bazÄ…
    try:
        conn = get_db_connection()
        logger.info("âœ“ PoÅ‚Ä…czono z bazÄ… danych")
    except Exception as e:
        logger.error(f"âŒ BÅ‚Ä…d poÅ‚Ä…czenia z bazÄ…: {e}")
        sys.exit(1)
    
    # Wczytaj postÄ™p jeÅ›li istnieje
    progress = load_progress(conn, args.ticker)
    if progress:
        try:
            resume_date = datetime.fromisoformat(progress['current_date'].replace('Z', '+00:00'))
            logger.info(f"ğŸ“Œ Wznawianie od daty: {resume_date.date()}")
            current_date = resume_date
        except:
            current_date = datetime.now(timezone.utc) - timedelta(days=args.days_back_start)
            logger.info(f"âš ï¸ BÅ‚Ä…d wczytywania postÄ™pu, zaczynam od {current_date.date()}")
    else:
        current_date = datetime.now(timezone.utc) - timedelta(days=args.days_back_start)
        logger.info(f"ğŸ“… Zaczynam od daty: {current_date.date()}")
    
    # Inicjalizuj provider
    provider = DydxIndexerProvider()
    
    days_processed = 0
    days_successful = 0
    days_failed = 0
    total_trades = 0
    
    try:
        while True:
            # PrzetwÃ³rz jeden dzieÅ„
            success, trades_count, attempts = process_single_day(
                provider=provider,
                conn=conn,
                ticker=args.ticker,
                target_date=current_date
            )
            
            days_processed += 1
            
            if success:
                days_successful += 1
                total_trades += trades_count
                
                # Zapisz postÄ™p
                save_progress(conn, args.ticker, current_date, total_trades, attempts)
                
                completed_date = current_date
                
                # PrzejdÅº do poprzedniego dnia
                current_date = current_date - timedelta(days=1)
                
                logger.info(f"âœ“ DzieÅ„ {completed_date.date()} zakoÅ„czony pomyÅ›lnie ({trades_count} transakcji). PrzechodzÄ™ do {current_date.date()}")
                
                # SprawdÅº limit dni
                if args.max_days and days_processed >= args.max_days:
                    logger.info(f"âœ“ OsiÄ…gniÄ™to limit {args.max_days} dni. Zatrzymywanie...")
                    break
                
                # OpÃ³Åºnienie miÄ™dzy dniami
                if args.delay_between_days > 0:
                    time.sleep(args.delay_between_days)
            else:
                days_failed += 1
                logger.error(f"âŒ BÅ‚Ä…d przetwarzania dnia {current_date.date()}. BÅ‚Ä™dy z rzÄ™du: {days_failed}. Ponawiam...")
                
                # Nie przechodzimy do nastÄ™pnego dnia - ponawiamy ten sam dzieÅ„
                # ZwiÄ™ksz opÃ³Åºnienie przed ponownÄ… prÃ³bÄ…
                wait_time = min(RETRY_DELAY_BASE * (2 ** min(days_failed, 5)), RETRY_DELAY_MAX)
                logger.info(f"â³ Czekam {wait_time:.0f}s przed ponownÄ… prÃ³bÄ… dnia {current_date.date()}...")
                time.sleep(wait_time)
    
    except KeyboardInterrupt:
        logger.warning("âš ï¸ Przerwano przez uÅ¼ytkownika")
        try:
            save_progress(conn, args.ticker, current_date, total_trades, [])
        except:
            pass  # Ignoruj bÅ‚Ä™dy przy zapisie postÄ™pu przy przerwaniu
    except Exception as e:
        logger.error(f"âŒ BÅ‚Ä…d krytyczny: {e}")
        import traceback
        logger.error(traceback.format_exc())
        try:
            save_progress(conn, args.ticker, current_date, total_trades, [])
        except:
            pass  # Ignoruj bÅ‚Ä™dy przy zapisie postÄ™pu przy bÅ‚Ä™dzie
    finally:
        if 'conn' in locals():
            conn.close()
        logger.info("="*70)
        logger.info("PODSUMOWANIE:")
        logger.info(f"  Dni przetworzone: {days_processed}")
        logger.info(f"  Dni zakoÅ„czone sukcesem: {days_successful}")
        logger.info(f"  Dni z bÅ‚Ä™dami: {days_failed}")
        logger.info(f"  ÅÄ…cznie transakcji: {total_trades}")
        logger.info("="*70)


if __name__ == '__main__':
    main()

